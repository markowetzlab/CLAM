{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "slide_matching_path = \"/mnt/scratchc/fmlab/zuberi01/masters/slide_matching.csv\"\n",
    "model_training_input_path = \"/mnt/scratchc/fmlab/zuberi01/masters/model_training_input_230815.csv\"\n",
    "\n",
    "slide_matching = []\n",
    "model_training_input = []\n",
    "\n",
    "with open(slide_matching_path, mode='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    for lines in csvFile:\n",
    "        slide_matching.append(lines)\n",
    "\n",
    "with open(model_training_input_path, mode='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    for lines in csvFile:\n",
    "        model_training_input.append(lines)\n",
    "\n",
    "slide_matching_PatientID_index = slide_matching[0].index('PatientID')\n",
    "slide_matching_all_PatientIDs = []\n",
    "for i in range(1, len(slide_matching)):\n",
    "    id = slide_matching[i][slide_matching_PatientID_index]\n",
    "    if id != '':\n",
    "        slide_matching_all_PatientIDs.append(int(float(id)))\n",
    "#print(np.unique(slide_matching_all_PatientIDs, return_counts=True)[1])\n",
    "\n",
    "model_training_input_PatientID_index = model_training_input[0].index('Patient ID')\n",
    "model_training_input_all_PatientIDs = []\n",
    "for i in range(1, len(model_training_input)):\n",
    "    id = model_training_input[i][model_training_input_PatientID_index]\n",
    "    if id != '':\n",
    "        model_training_input_all_PatientIDs.append(int(float(id)))\n",
    "\n",
    "#print(np.unique(model_training_input_all_PatientIDs, return_counts=True)[1])\n",
    "\n",
    "# check in slide_matching there are any duplicate rows\n",
    "# if num of rows and num of unique is the same then there are no duplicates\n",
    "#print(len(slide_matching))\n",
    "#print(len(set([tuple(i) for i in slide_matching])))\n",
    "#print(len(set([tuple(i) for i in model_training_input])))\n",
    "#print(len(model_training_input))\n",
    "\n",
    "slide_matching_year_index = slide_matching[0].index('EndoscopyDate')\n",
    "model_training_input_months_before_final_index = model_training_input[0].index('Months before final')\n",
    "\n",
    "slide_matching_block_index = slide_matching[0].index('Block')\n",
    "model_training_input_esophageal_location_index = model_training_input[0].index('Esophageal location')\n",
    "\n",
    "def match_endoscopies_with_indices(list1, list2):\n",
    "        # Sort list1 by year (descending) and list2 by months (ascending)\n",
    "        #print(len(list1),len(list2))\n",
    "        list1_sorted = enumerate(list1, start=1)\n",
    "        list2_sorted = enumerate(list2, start=1)\n",
    "        \n",
    "        # Initialize the list for matches\n",
    "        matches = []\n",
    "        used_indices = set()\n",
    "        \n",
    "        # Match entries from list1 and list2 starting from the largest year to the smallest with the smallest month to the largest\n",
    "        for i, (year, location1) in list1_sorted:\n",
    "                if location1 == '':\n",
    "                        continue\n",
    "                for j, (months, location2) in list2_sorted:\n",
    "                        if j not in used_indices and location1 == location2:\n",
    "                                matches.append((i, j))\n",
    "                                used_indices.add(j)\n",
    "                                break\n",
    "        \n",
    "        # Add edge cases for unmatched entries\n",
    "        unmatched_list1 = [i for i, (year, location1) in list1_sorted if location1 == '' or not any(location1 == loc for _, (months, loc) in list2_sorted)]\n",
    "        unmatched_list2 = [j for j, (months, location2) in list2_sorted if j not in used_indices]\n",
    "\n",
    "        # now if there are duplicates in the list1_sorted or list2_sorted we remove those matches\n",
    "        elements_of_list1 = [list1[matches[i][0]-1] for i in range(len(matches))]\n",
    "        elements_of_list2 = [list2[matches[i][1]-1] for i in range(len(matches))]\n",
    "\n",
    "        #check if there are duplicates in list1 and get their indices\n",
    "        duplicates_list1 = []\n",
    "\n",
    "        matches_elements_and_indices = []\n",
    "        for match in matches:\n",
    "                #print(match)\n",
    "                list1_match = list1[match[0]-1]\n",
    "                first = [list1_match, match[0]-1]\n",
    "\n",
    "                list2_match = list2[match[1]-1]\n",
    "                second = [list2_match, match[1]-1]\n",
    "\n",
    "                matches_elements_and_indices.append((first,second))\n",
    "                \n",
    "        #print(matches_elements_and_indices)\n",
    "        \n",
    "        #print(elements_of_list1)\n",
    "        #print(elements_of_list2)\n",
    "        return matches\n",
    "\n",
    "# create a new CSV file which will have the matching rows from slide_matching and model_training_input\n",
    "new_csv = []\n",
    "# add as the first row the headers from slide_matching and model_training_input\n",
    "slide_matching_renamed_rows = []\n",
    "for i in slide_matching[0]:\n",
    "    slide_matching_renamed_rows.append(i + '_SM')\n",
    "\n",
    "model_training_input_renamed_rows = []\n",
    "for i in model_training_input[0]:\n",
    "    model_training_input_renamed_rows.append(i + '_MT230815')\n",
    "\n",
    "new_csv.append(slide_matching_renamed_rows + model_training_input_renamed_rows)\n",
    "\n",
    "print(len(new_csv))\n",
    "\n",
    "# take each row in model_training_input and find its match\n",
    "# we have to separate them per Patient ID\n",
    "rows_excluded = 0\n",
    "rows_in = 0\n",
    "index_for_all = 1\n",
    "num_matches = 0\n",
    "current_row_in_new_csv = 1\n",
    "\n",
    "pat_ids = 0\n",
    "for patient_id in np.unique(model_training_input_all_PatientIDs):\n",
    "    # get the rows in slide_matching that have the same patient_id\n",
    "    slide_matching_rows = []\n",
    "    for i in range(1, len(slide_matching)):\n",
    "        if slide_matching[i][slide_matching_PatientID_index] != '' and int(float(slide_matching[i][slide_matching_PatientID_index])) == patient_id:\n",
    "            row = slide_matching[i]\n",
    "\n",
    "            # now we will change the date format to just be the year and be an int\n",
    "            row[slide_matching_year_index] = int(float(row[slide_matching_year_index][:4]))\n",
    "\n",
    "            slide_matching_rows.append(row)\n",
    "    # sort slide_matching_rows by the years\n",
    "    slide_matching_rows = sorted(slide_matching_rows, key=lambda x: x[slide_matching_year_index], reverse=False)\n",
    "    # print just the patient_id and the years\n",
    "    slide_matching_rows_years = []\n",
    "    for i in slide_matching_rows:\n",
    "        slide_matching_rows_years.append(i[slide_matching_year_index])\n",
    "\n",
    "    #print(slide_matching_rows)\n",
    "\n",
    "    # get the row in model_training_input that has the same patient_id\n",
    "    model_training_input_rows = []\n",
    "    for i in range(1, len(model_training_input)):\n",
    "        if model_training_input[i][model_training_input_PatientID_index] != '' and int(float(model_training_input[i][model_training_input_PatientID_index])) == patient_id:\n",
    "            \n",
    "            row = model_training_input[i]\n",
    "\n",
    "            # now we will change the date format to just be the year and be an int\n",
    "            row[model_training_input_months_before_final_index] = int(float(row[model_training_input_months_before_final_index]))\n",
    "\n",
    "            model_training_input_rows.append(model_training_input[i])\n",
    "    # sort model_training_input_rows by the months before final\n",
    "    model_training_input_rows = sorted(model_training_input_rows, key=lambda x: x[model_training_input_months_before_final_index], reverse=True)\n",
    "    model_training_input_rows_months_before_final = []\n",
    "    for i in model_training_input_rows:\n",
    "        model_training_input_rows_months_before_final.append(i[model_training_input_months_before_final_index])\n",
    "\n",
    "    \n",
    "\n",
    "    #rows_in += len(slide_matching_rows)\n",
    "    #if len(slide_matching_rows) != len(set(slide_matching_rows_years)) and len(model_training_input_rows) != len(set(model_training_input_rows_months_before_final)):\n",
    "\n",
    "        #rows_excluded += len(slide_matching_rows) \n",
    "\n",
    "        #print(\"ERROR, duplicate years in slide_matching_rows\")\n",
    "        #if len(model_training_input_rows) != len(set(model_training_input_rows_months_before_final)):\n",
    "        #    print(\"ERROR, duplicate years in model_training_input_rows\")\n",
    "\n",
    "       \n",
    "\n",
    "    #first clean up the slide_matching_rows' block locations to just keep the integers and then sort them\n",
    "    #sort them by the years first and then by block locations\n",
    "    for j, row in enumerate(slide_matching_rows):\n",
    "        block = row[slide_matching_block_index]\n",
    "        # only keep the integers and if there is nothing left print it and break\n",
    "        block = ''.join(filter(str.isdigit, block))\n",
    "        #if block == '':\n",
    "        #    print('Block:', row[slide_matching_block_index])\n",
    "        #    break\n",
    "        slide_matching_rows[j][slide_matching_block_index] = block\n",
    "    #slide_matching_rows = sorted(slide_matching_rows, key=lambda x: (x[slide_matching_year_index], x[slide_matching_block_index]), reverse=False)\n",
    "\n",
    "    #sort the model_training_input_rows first by months_before_final and then by esophageal location\n",
    "    #model_training_input_rows = sorted(model_training_input_rows, key=lambda x: (x[model_training_input_months_before_final_index], x[model_training_input_esophageal_location_index]), reverse=False)\n",
    "    #for j in model_training_input_rows:\n",
    "    #    print(j)\n",
    "\n",
    "    #print('Patient id:', patient_id)\n",
    "\n",
    "    slide_matching_to_match = []\n",
    "    slide_matching_full_rows = []\n",
    "    for j in slide_matching_rows:\n",
    "        #print(j[slide_matching_block_index],type(j[slide_matching_block_index]))\n",
    "        year = j[slide_matching_year_index]\n",
    "        loc = j[slide_matching_block_index]\n",
    "        if loc != '': loc = int(float(loc))\n",
    "        slide_matching_full_rows.append(j)\n",
    "        slide_matching_to_match.append((year, loc))\n",
    "    #print(slide_matching_to_match)\n",
    "        #print(j[slide_matching_year_index],j[slide_matching_block_index])\n",
    "\n",
    "    model_training_to_match = []\n",
    "    model_training_full_rows = []\n",
    "    for j in model_training_input_rows:\n",
    "        months = j[model_training_input_months_before_final_index]\n",
    "        loc = j[model_training_input_esophageal_location_index]\n",
    "        if loc != '': loc= int(float(loc))\n",
    "        model_training_to_match.append((months,loc))\n",
    "        model_training_full_rows.append(j)\n",
    "        #print(j[model_training_input_months_before_final_index],j[model_training_input_esophageal_location_index])\n",
    "    #print(model_training_to_match)\n",
    "    #print('\\n')\n",
    "\n",
    "    #for j in range(len(slide_matching_rows)):\n",
    "    #    slide_matching_rows[j].append(index_for_all)\n",
    "    #    model_training_input_rows[j].append(index_for_all)\n",
    "    #    index_for_all += 1\n",
    "\n",
    "    length_of_both_avg = (len(slide_matching_to_match) + len(model_training_to_match))/2\n",
    "    #print(slide_matching_to_match)\n",
    "    #print(len(slide_matching_to_match),len(model_training_to_match))\n",
    "    matches = match_endoscopies_with_indices(slide_matching_to_match, model_training_to_match)\n",
    "    #print(len(matches))\n",
    "    #for match in matches:\n",
    "    #    print(slide_matching_to_match[match[0] - 1], model_training_to_match[match[1] - 1])\n",
    "    num_matches += len(matches)\n",
    "\n",
    "    # now I want to create CSV which merges every column from slide_matching.csv and model_training_input_230815.csv with every matching row put together\n",
    "    # I want to rename each column by their original CSV so EndoscopySampleID becomes EndoscopySampleID_SM (SM is for slide matching)\n",
    "    # Esophageal location becomes Esophageal location_MT230815 (MT230815 is for model training 230815)\n",
    "\n",
    "    new_row_in_csv = []\n",
    "    for match in matches:\n",
    "        #print(slide_matching_rows[match[0] - 1])\n",
    "        #print(model_training_input_rows[match[1] - 1])\n",
    "        new_row_in_csv = slide_matching_full_rows[match[0] - 1] + model_training_full_rows[match[1] - 1]\n",
    "\n",
    "        new_csv.append(new_row_in_csv)\n",
    "\n",
    "print(pat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Invalid Block 'B' for PatientID 3\n",
      "Warning: Invalid Block 'BB' for PatientID 4\n",
      "Warning: Invalid Block '' for PatientID 4\n",
      "Warning: Invalid Block '' for PatientID 6\n",
      "Warning: Invalid Block 'BA' for PatientID 6\n",
      "Warning: Invalid Block 'BB' for PatientID 6\n",
      "Warning: Invalid Block 'BC' for PatientID 6\n",
      "Warning: Invalid Block 'BB' for PatientID 9\n",
      "Warning: Invalid Block '' for PatientID 10\n",
      "Warning: Invalid Block '' for PatientID 10\n",
      "Warning: Invalid Block '' for PatientID 10\n",
      "Warning: Invalid Block 'BA' for PatientID 11\n",
      "Warning: Invalid Block 'BA' for PatientID 11\n",
      "Warning: Invalid Block 'BA' for PatientID 11\n",
      "Warning: Invalid Block 'BA' for PatientID 11\n",
      "Warning: Invalid Block 'BB' for PatientID 11\n",
      "Warning: Invalid Block 'Bb' for PatientID 12\n",
      "Warning: Invalid Block '' for PatientID 18\n",
      "Warning: Invalid Block 'BA' for PatientID 26\n",
      "Warning: Invalid Block 'BB' for PatientID 26\n",
      "Warning: Invalid Block 'BA' for PatientID 31\n",
      "Warning: Invalid Block '' for PatientID 39\n",
      "Warning: Invalid Block '' for PatientID 40\n",
      "Warning: Invalid Block 'BA' for PatientID 52\n",
      "Warning: Invalid Block 'BB' for PatientID 52\n",
      "Warning: Invalid Block 'BC' for PatientID 52\n",
      "Warning: Invalid Block 'Ba' for PatientID 55\n",
      "Warning: Invalid Block 'BA' for PatientID 71\n",
      "Warning: Invalid Block 'BB' for PatientID 71\n",
      "Warning: Invalid Block 'BC' for PatientID 71\n",
      "Warning: Invalid Block '' for PatientID 73\n",
      "Warning: Invalid Block '' for PatientID 74\n",
      "Warning: Invalid Block '' for PatientID 74\n",
      "Warning: Invalid Block 'BA' for PatientID 74\n",
      "Warning: Invalid Block 'BB' for PatientID 74\n",
      "Warning: Invalid Block 'BC' for PatientID 74\n",
      "Warning: Invalid Block 'BD/I?' for PatientID 74\n",
      "Warning: Invalid Block '' for PatientID 75\n",
      "Warning: Invalid Block '' for PatientID 75\n",
      "Warning: Invalid Block 'BA' for PatientID 76\n",
      "Warning: Invalid Block 'BB' for PatientID 76\n",
      "Warning: Invalid Block 'BA' for PatientID 77\n",
      "Warning: Invalid Block 'BD' for PatientID 77\n",
      "Warning: Invalid Block '' for PatientID 78\n",
      "Warning: Invalid Block 'BA' for PatientID 79\n",
      "Warning: Invalid Block 'BB' for PatientID 79\n",
      "Warning: Invalid Block 'BA' for PatientID 80\n",
      "Warning: Invalid Block 'BB' for PatientID 80\n",
      "Warning: Invalid Block 'BA' for PatientID 85\n",
      "Warning: Invalid Block 'BA' for PatientID 85\n",
      "Warning: Invalid Block 'BA' for PatientID 87\n",
      "Warning: Invalid Block 'BA' for PatientID 87\n",
      "Warning: Invalid Block 'BA' for PatientID 87\n",
      "Warning: Invalid Block 'BA' for PatientID 87\n",
      "Warning: Invalid Block 'BA' for PatientID 87\n",
      "Warning: Invalid Block 'BA' for PatientID 88\n",
      "Warning: Invalid Block 'BA' for PatientID 88\n",
      "Warning: Invalid Block 'BA' for PatientID 88\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/output.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 138\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Optionally, write the new CSV data to a file\u001b[39;00m\n\u001b[1;32m    137\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/path/to/output.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    139\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(file)\n\u001b[1;32m    140\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwriterows(new_csv)\n",
      "File \u001b[0;32m/home/zuberi01/miniforge3/envs/clam_latest/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/output.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Define file paths\n",
    "slide_matching_path = \"/mnt/scratchc/fmlab/zuberi01/masters/slide_matching.csv\"\n",
    "model_training_input_path = \"/mnt/scratchc/fmlab/zuberi01/masters/model_training_input_230815.csv\"\n",
    "\n",
    "# Initialize data lists\n",
    "slide_matching = []\n",
    "model_training_input = []\n",
    "\n",
    "# Read slide_matching.csv into a list of dictionaries\n",
    "with open(slide_matching_path, mode='r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        slide_matching.append(row)\n",
    "\n",
    "# Read model_training_input_230815.csv into a list of dictionaries\n",
    "with open(model_training_input_path, mode='r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        model_training_input.append(row)\n",
    "\n",
    "# Group slide_matching rows by PatientID\n",
    "slide_matching_by_patient = defaultdict(list)\n",
    "for row in slide_matching:\n",
    "    patient_id = row.get('PatientID', '').strip()\n",
    "    if patient_id:\n",
    "        try:\n",
    "            patient_id_num = int(float(patient_id))\n",
    "            slide_matching_by_patient[patient_id_num].append(row)\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Invalid PatientID '{patient_id}' in slide_matching\")\n",
    "            continue\n",
    "\n",
    "# Group model_training_input rows by Patient ID\n",
    "model_training_by_patient = defaultdict(list)\n",
    "for row in model_training_input:\n",
    "    patient_id = row.get('Patient ID', '').strip()\n",
    "    if patient_id:\n",
    "        try:\n",
    "            patient_id_num = int(float(patient_id))\n",
    "            model_training_by_patient[patient_id_num].append(row)\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Invalid Patient ID '{patient_id}' in model_training_input\")\n",
    "            continue\n",
    "\n",
    "# Get the set of common patient IDs\n",
    "common_patient_ids = set(slide_matching_by_patient.keys()).intersection(set(model_training_by_patient.keys()))\n",
    "\n",
    "# Prepare headers for the new CSV\n",
    "slide_matching_headers = slide_matching[0].keys()\n",
    "slide_matching_renamed_headers = [h + '_SM' for h in slide_matching_headers]\n",
    "\n",
    "model_training_headers = model_training_input[0].keys()\n",
    "model_training_renamed_headers = [h + '_MT230815' for h in model_training_headers]\n",
    "\n",
    "# Initialize the new CSV data\n",
    "new_csv = []\n",
    "new_csv.append(slide_matching_renamed_headers + model_training_renamed_headers)\n",
    "\n",
    "def match_endoscopies_with_indices(list1, list2):\n",
    "    \"\"\"\n",
    "    Match entries from list1 and list2 based on location.\n",
    "    Each list contains tuples of (value, location).\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    used_indices = set()\n",
    "    for idx1, (val1, loc1) in enumerate(list1):\n",
    "        for idx2, (val2, loc2) in enumerate(list2):\n",
    "            if idx2 in used_indices:\n",
    "                continue\n",
    "            if loc1 == loc2:\n",
    "                matches.append((idx1, idx2))\n",
    "                used_indices.add(idx2)\n",
    "                break\n",
    "    return matches\n",
    "\n",
    "# Process each common patient ID\n",
    "for patient_id in common_patient_ids:\n",
    "    slide_rows = slide_matching_by_patient[patient_id]\n",
    "    model_rows = model_training_by_patient[patient_id]\n",
    "    \n",
    "    # Prepare data for matching\n",
    "    slide_data = []\n",
    "    for row in slide_rows:\n",
    "        # Extract and validate EndoscopyDate (year)\n",
    "        endoscopy_date = row.get('EndoscopyDate', '').strip()\n",
    "        try:\n",
    "            year = int(endoscopy_date[:4])\n",
    "        except (ValueError, IndexError):\n",
    "            print(f\"Warning: Invalid EndoscopyDate '{endoscopy_date}' for PatientID {patient_id}\")\n",
    "            continue\n",
    "        # Extract and validate Block (location)\n",
    "        block = row.get('Block', '').strip()\n",
    "        block_digits = ''.join(filter(str.isdigit, block))\n",
    "        if not block_digits:\n",
    "            print(f\"Warning: Invalid Block '{block}' for PatientID {patient_id}\")\n",
    "            continue\n",
    "        location = int(block_digits)\n",
    "        slide_data.append({'year': year, 'location': location, 'row': row})\n",
    "    \n",
    "    model_data = []\n",
    "    for row in model_rows:\n",
    "        # Extract and validate Months before final\n",
    "        months_before_final = row.get('Months before final', '').strip()\n",
    "        try:\n",
    "            months = int(float(months_before_final))\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Invalid Months before final '{months_before_final}' for PatientID {patient_id}\")\n",
    "            continue\n",
    "        # Extract and validate Esophageal location\n",
    "        esophageal_location = row.get('Esophageal location', '').strip()\n",
    "        loc_digits = ''.join(filter(str.isdigit, esophageal_location))\n",
    "        if not loc_digits:\n",
    "            print(f\"Warning: Invalid Esophageal location '{esophageal_location}' for PatientID {patient_id}\")\n",
    "            continue\n",
    "        location = int(loc_digits)\n",
    "        model_data.append({'months': months, 'location': location, 'row': row})\n",
    "    \n",
    "    # Create lists for matching\n",
    "    slide_match_list = [(item['year'], item['location']) for item in slide_data]\n",
    "    model_match_list = [(item['months'], item['location']) for item in model_data]\n",
    "    \n",
    "    # Perform matching\n",
    "    matches = match_endoscopies_with_indices(slide_match_list, model_match_list)\n",
    "    \n",
    "    # Combine matched rows\n",
    "    for idx1, idx2 in matches:\n",
    "        slide_row = slide_data[idx1]['row']\n",
    "        model_row = model_data[idx2]['row']\n",
    "        combined_row = [slide_row[h] for h in slide_matching_headers] + [model_row[h] for h in model_training_headers]\n",
    "        new_csv.append(combined_row)\n",
    "\n",
    "# Optionally, write the new CSV data to a file\n",
    "#output_path = \"/path/to/output.csv\"\n",
    "#with open(output_path, mode='w', newline='') as file:\n",
    "#    writer = csv.writer(file)\n",
    "#    writer.writerows(new_csv)\n",
    "\n",
    "print(\"Data processing complete. The new CSV file has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"matching_rows.csv\"\n",
    "with open(output_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(new_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  Block_model  Patient ID Status  Esophageal location Pathology2  \\\n",
      "0      1            1           1      P                    1       NDBE   \n",
      "1      2            1           1      P                    1       NDBE   \n",
      "2      3            1           1      P                    1        LGD   \n",
      "3      4            1           2      P                    1       NDBE   \n",
      "4      5            3           2      P                    3       NDBE   \n",
      "\n",
      "   Months before final  OGD_ID OGD_pathology classification  ... Block_slide  \\\n",
      "0                  120       1          NDBE         NDBE_P  ...          B1   \n",
      "1                   96       2          NDBE         NDBE_P  ...          B1   \n",
      "2                   48       3           LGD          LGD_P  ...          B1   \n",
      "3                   60       4          NDBE         NDBE_P  ...          B1   \n",
      "4                   60       4          NDBE         NDBE_P  ...          B3   \n",
      "\n",
      "   BlockLevel  label  p53IHC       Site  SampleType  \\\n",
      "0         NaN   NDBE  normal  Cambridge        FFPE   \n",
      "1         NaN   NDBE  normal  Cambridge        FFPE   \n",
      "2         NaN    LGD  normal  Cambridge        FFPE   \n",
      "3         NaN   NDBE  normal  Cambridge        FFPE   \n",
      "4         NaN   NDBE     NaN  Cambridge        FFPE   \n",
      "\n",
      "                        Notes  New Name (Nov 2020)                 slide_id  \\\n",
      "0                ps94.3856_B1                  NaN    S94 3856 1 G3497.ndpi   \n",
      "1               ps96.13273_B1                  NaN   S96 13273 1 G3497.ndpi   \n",
      "2               ps00.18908_B1                  NaN  PS00 18908 B2100 1.ndpi   \n",
      "3  ps96.3013_B1; ps96.3013_B3                  NaN  S96 3013 A 1 G3497.ndpi   \n",
      "4  ps96.3013_B1; ps96.3013_B3                  NaN  S96 3013 C 1 G3497.ndpi   \n",
      "\n",
      "   Slide Notes  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 629 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "slide_matching_path = \"/mnt/scratchc/fmlab/zuberi01/masters/slide_matching.csv\"\n",
    "model_training_input_path = \"/mnt/scratchc/fmlab/zuberi01/masters/model_training_input_230815.csv\"\n",
    "\n",
    "\n",
    "# Read the CSV files\n",
    "df_model = pd.read_csv(model_training_input_path)\n",
    "df_slide = pd.read_csv(slide_matching_path)\n",
    "\n",
    "# Ensure 'Patient ID' and 'OGD_ID' in df_model are integers\n",
    "df_model['Patient ID'] = pd.to_numeric(df_model['Patient ID'], errors='coerce').astype('Int64')\n",
    "df_model['OGD_ID'] = pd.to_numeric(df_model['OGD_ID'], errors='coerce').astype('Int64')\n",
    "df_model['Block'] = pd.to_numeric(df_model['Block'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Create 'Block_str' in df_model (e.g., 'B1', 'B2', etc.)\n",
    "df_model['Block_str'] = 'B' + df_model['Block'].astype(str)\n",
    "\n",
    "# Ensure 'PatientID' and 'EndoscopyID' in df_slide are integers\n",
    "df_slide['PatientID'] = pd.to_numeric(df_slide['PatientID'], errors='coerce').astype('Int64')\n",
    "df_slide['EndoscopyID'] = pd.to_numeric(df_slide['EndoscopyID'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Clean 'Block' in df_slide (ensure it's uppercase and stripped of whitespace)\n",
    "df_slide['Block'] = df_slide['Block'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Parse 'EndoscopyDate' in df_slide to datetime\n",
    "df_slide['EndoscopyDate'] = pd.to_datetime(df_slide['EndoscopyDate'], errors='coerce')\n",
    "\n",
    "# Create a dictionary to store the final dates for each patient\n",
    "final_dates = {}\n",
    "\n",
    "# Identify the final date for each patient\n",
    "for patient_id in df_model['Patient ID'].unique():\n",
    "    df_patient = df_model[df_model['Patient ID'] == patient_id]\n",
    "    df_final = df_patient[df_patient['Months before final'] == 0]\n",
    "    if not df_final.empty:\n",
    "        final_ogd_ids = df_final['OGD_ID'].unique()\n",
    "        for ogd_id in final_ogd_ids:\n",
    "            df_slide_match = df_slide[(df_slide['PatientID'] == patient_id) & (df_slide['EndoscopyID'] == ogd_id)]\n",
    "            if not df_slide_match.empty:\n",
    "                endoscopy_date = df_slide_match.iloc[0]['EndoscopyDate']\n",
    "                final_dates[patient_id] = endoscopy_date\n",
    "                break\n",
    "\n",
    "# Compute 'EndoscopyDate' in df_model based on 'Months before final'\n",
    "def compute_endoscopy_date(row):\n",
    "    patient_id = row['Patient ID']\n",
    "    months_before_final = row['Months before final']\n",
    "    if patient_id in final_dates and pd.notnull(final_dates[patient_id]):\n",
    "        final_date = final_dates[patient_id]\n",
    "        endoscopy_date = final_date - pd.DateOffset(months=months_before_final)\n",
    "        return endoscopy_date\n",
    "    else:\n",
    "        return pd.NaT\n",
    "\n",
    "df_model['EndoscopyDate'] = df_model.apply(compute_endoscopy_date, axis=1)\n",
    "\n",
    "# Merge the DataFrames on 'Patient ID', 'OGD_ID', and 'Block'\n",
    "df_merged = pd.merge(\n",
    "    df_model,\n",
    "    df_slide,\n",
    "    left_on=['Patient ID', 'OGD_ID', 'Block_str'],\n",
    "    right_on=['PatientID', 'EndoscopyID', 'Block'],\n",
    "    how='left',\n",
    "    suffixes=('_model', '_slide')\n",
    ")\n",
    "\n",
    "# Optional: If you want to match on 'EndoscopyDate' as well (allowing for exact date matches)\n",
    "# Merge on 'Patient ID', 'EndoscopyDate', and 'Block'\n",
    "# Note: This step assumes that dates match exactly, which might not always be the case\n",
    "# df_merged = pd.merge(\n",
    "#     df_model,\n",
    "#     df_slide,\n",
    "#     left_on=['Patient ID', 'EndoscopyDate', 'Block_str'],\n",
    "#     right_on=['PatientID', 'EndoscopyDate', 'Block'],\n",
    "#     how='left',\n",
    "#     suffixes=('_model', '_slide')\n",
    "# )\n",
    "\n",
    "# Save the merged DataFrame to a CSV file\n",
    "df_merged.to_csv('merged_output.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the merged DataFrame\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758\n"
     ]
    }
   ],
   "source": [
    "print(len(df_merged))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clam_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
